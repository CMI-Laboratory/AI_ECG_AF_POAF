{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "from efficientnet_architecture import efficientnet_b0 as efficientnetb0 #Ensure the \"efficientnet_architecture.py\" file is in the same directory as this notebook\n",
    "\n",
    "device='cuda' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def znorm(tensor):\n",
    "    avg = tensor.mean(dim=-1,keepdim=True)\n",
    "    std = tensor.std(dim=-1,keepdim=True)\n",
    "    return (tensor-avg)/(std+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('df_train.csv')\n",
    "df_val=pd.read_csv('df_val.csv')\n",
    "df_test=pd.read_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9729c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_train=torch.load('wf_train.pt')\n",
    "wf_val=torch.load('wf_val.pt')\n",
    "wf_test=torch.load('wf_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_train=znorm(wf_train)\n",
    "wf_val=znorm(wf_val)\n",
    "wf_test=znorm(wf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df_train,df_val,df_test,bs,lr,weight_decay,epoch_num,optimizer_type,label,trainvaltest_iter,themodel,modelname,savepath):\n",
    "    try:\n",
    "        os.mkdir(savepath+modelname+'_'+str(bs)+'_'+str(lr))\n",
    "    except:\n",
    "        pass\n",
    "    savepath=(savepath+modelname+'_'+str(bs)+'_'+str(lr)+'/')\n",
    "    \n",
    "    class Afib_train(Dataset):\n",
    "        def __init__(self):\n",
    "            self.thedf=df_train\n",
    "            self.len=len(self.thedf)\n",
    "\n",
    "        def __getitem__(self,index):\n",
    "            self.input=wf_train[index]\n",
    "            self.output=self.thedf[label][index]\n",
    "            return self.input,self.output\n",
    "\n",
    "        def get_labels(self): \n",
    "            return np.array(self.thedf[label])\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.len\n",
    "        \n",
    "    class Afib_val(Dataset):\n",
    "        def __init__(self):\n",
    "            self.thedf=df_val\n",
    "            self.len=len(self.thedf)\n",
    "\n",
    "        def __getitem__(self,index):\n",
    "            self.input=wf_val[index]\n",
    "            self.output=self.thedf[label][index]\n",
    "            return self.input,self.output\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.len\n",
    "\n",
    "\n",
    "    class Afib_test(Dataset):\n",
    "        def __init__(self):\n",
    "            self.thedf=df_test\n",
    "            self.len=len(self.thedf)\n",
    "\n",
    "        def __getitem__(self,index):\n",
    "            self.input=wf_test[index]\n",
    "            self.output=self.thedf[label][index]\n",
    "            return self.input,self.output\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.len\n",
    "\n",
    "\n",
    "    train_dataset = Afib_train()\n",
    "    val_dataset = Afib_val()\n",
    "    test_dataset = Afib_test()\n",
    "\n",
    "    train_dataset_dataloader = DataLoader(train_dataset,batch_size=bs, sampler=ImbalancedDatasetSampler(train_dataset))\n",
    "    val_dataset_dataloader = DataLoader(val_dataset,batch_size=bs)\n",
    "    test_dataset_dataloader = DataLoader(test_dataset,batch_size=bs)\n",
    "\n",
    "    model=themodel\n",
    "    criterion=nn.CrossEntropyLoss().to(device)\n",
    "    if optimizer_type=='Adam':\n",
    "        optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    elif optimizer_type=='RMSprop':\n",
    "        optimizer=torch.optim.RMSprop(model.parameters(),lr=lr, weight_decay=weight_decay,alpha=0.9, momentum=0.1)\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=0.5,mode='min')\n",
    "\n",
    "    bestAUROC=0\n",
    "    accum=0\n",
    "    toggle=0\n",
    "    targets_test=[]\n",
    "    prediction_test=[]\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        if toggle==1:\n",
    "            break \n",
    "\n",
    "        now1=datetime.datetime.now()\n",
    "        for phase in trainvaltest_iter:\n",
    "            if phase=='training':\n",
    "                running_loss=0.0\n",
    "                acc=0.\n",
    "                correct=0\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(param_group['lr']) \n",
    "                TP=0\n",
    "                TN=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                model.train()\n",
    "                for i,data in enumerate(train_dataset_dataloader):\n",
    "                    inputs,targets=data\n",
    "                    inputs=inputs.to(device)\n",
    "                    targets=targets.long().to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs,outputssoft=model(inputs)\n",
    "                    loss=criterion(outputs,targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss+=loss.item()\n",
    "                    prediction=torch.max(outputs.data,1)[1]\n",
    "                    correct+=prediction.eq(targets.data.view_as(prediction)).cpu().sum()\n",
    "                    for a,b in zip(targets,prediction):\n",
    "                        if a==1 and b==1:\n",
    "                            TP+=1\n",
    "                        elif a==1 and b==0:\n",
    "                            FN+=1\n",
    "                        elif a==0 and b==1:\n",
    "                            FP+=1\n",
    "                        else:\n",
    "                            TN+=1 \n",
    "                \n",
    "                print(\"[%d] loss: %.3f  \" % (epoch+1,running_loss/100))     \n",
    "\n",
    "            if phase=='val':\n",
    "                model.eval()\n",
    "                running_loss=0.0\n",
    "                acc=0.\n",
    "                correct=0\n",
    "                TP=0\n",
    "                TN=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                prediction_score=[]\n",
    "                targets_list=[]\n",
    "                with torch.no_grad():\n",
    "                    for i,data in enumerate(val_dataset_dataloader):\n",
    "                        inputs,targets=data\n",
    "                        for j in range(len(targets)):\n",
    "                            targets_list.append(targets[j])\n",
    "                        inputs=inputs.to(device)\n",
    "                        targets=targets.long().to(device)\n",
    "                        outputs,outputssoft=model(inputs)\n",
    "                        loss=criterion(outputs,targets)\n",
    "                        running_loss+=loss.item()\n",
    "                        prediction=torch.max(outputs.data,1)[1]\n",
    "                        correct+=prediction.eq(targets.data.view_as(prediction)).cpu().sum()\n",
    "\n",
    "                        for a,b in zip(targets,prediction):\n",
    "                            if a==1 and b==1:\n",
    "                                TP+=1\n",
    "                            elif a==1 and b==0:\n",
    "                                FN+=1\n",
    "                            elif a==0 and b==1:\n",
    "                                FP+=1\n",
    "                            else:\n",
    "                                TN+=1\n",
    "                        for j in range(len(outputssoft)):\n",
    "                            prediction_score.append(outputssoft[j][1].item())\n",
    "               \n",
    "                fpr_temp,tpr_temp,threshold=metrics.roc_curve(targets_list,prediction_score,pos_label=1)\n",
    "                AUROC=metrics.auc(fpr_temp,tpr_temp)\n",
    "                AP=average_precision_score(targets_list,prediction_score)\n",
    "\n",
    "                print(\"[%d] loss: %.3f AUROC: %.3f AUPRC: %.3f \" % (epoch+1,running_loss/100,AUROC,AP))     \n",
    "                scheduler.step(running_loss)\n",
    "                \n",
    "                if epoch==0:\n",
    "                    lowest_val_loss=running_loss\n",
    "                else:\n",
    "                    if running_loss<lowest_val_loss:\n",
    "                        lowest_val_loss=running_loss\n",
    "                        accum=0\n",
    "                    else:\n",
    "                        accum+=1\n",
    "                    if accum==15:\n",
    "                        toggle=1\n",
    "\n",
    "            if phase=='test':\n",
    "                model.eval()\n",
    "                running_loss=0.0\n",
    "                acc=0.\n",
    "                correct=0\n",
    "                TP=0\n",
    "                TN=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                prediction_score=[]\n",
    "                targets_list=[]\n",
    "                with torch.no_grad():\n",
    "                    for i,data in enumerate(test_dataset_dataloader):\n",
    "                        inputs,targets=data\n",
    "                        for j in range(len(targets)):\n",
    "                            targets_list.append(targets[j])\n",
    "                        inputs=inputs.to(device)\n",
    "                        targets=targets.long().to(device)\n",
    "                        outputs,outputssoft=model(inputs)\n",
    "                        loss=criterion(outputs,targets)\n",
    "                        running_loss+=loss.item()\n",
    "                        prediction=torch.max(outputs.data,1)[1]\n",
    "                        correct+=prediction.eq(targets.data.view_as(prediction)).cpu().sum()\n",
    "\n",
    "                        for a,b in zip(targets,prediction):\n",
    "                            if a==1 and b==1:\n",
    "                                TP+=1\n",
    "                            elif a==1 and b==0:\n",
    "                                FN+=1\n",
    "                            elif a==0 and b==1:\n",
    "                                FP+=1\n",
    "                            else:\n",
    "                                TN+=1\n",
    "                        for j in range(len(outputssoft)):\n",
    "                            prediction_score.append(outputssoft[j][1].item())\n",
    "\n",
    "                try:\n",
    "                    sensitivity=(TP/(TP+FN))\n",
    "                except:\n",
    "                    sensitivity=0.5\n",
    "                try:\n",
    "                    specificity=(TN/(TN+FP))\n",
    "                except:\n",
    "                    specificity=0.5\n",
    "                try:\n",
    "                    precision=(TP/(TP+FP))\n",
    "                except:\n",
    "                    precision=0\n",
    "                if precision!=0:\n",
    "                    f1score=((2*precision*sensitivity)/(precision+sensitivity))\n",
    "                else:\n",
    "                    f1score=0                \n",
    "                \n",
    "                fpr_temp,tpr_temp,threshold=metrics.roc_curve(targets_list,prediction_score,pos_label=1)\n",
    "                AUROC=metrics.auc(fpr_temp,tpr_temp)\n",
    "                AP=average_precision_score(targets_list,prediction_score)\n",
    "\n",
    "                print(\"[%d] loss: %.3f AUROC: %.3f AUPRC: %.3f \" % (epoch+1,running_loss/100,AUROC,AP))     \n",
    "                \n",
    "                now = datetime.datetime.now()\n",
    "                nowStr2 = \"{:%Y%m%d%H%M%S}\".format(now)\n",
    "                modelname2=nowStr2+'_'\n",
    "                modelname2+=(label+'_')\n",
    "                modelname2+=modelname\n",
    "                modelname2+=('_'+'epoch_'+str(epoch))\n",
    "                modelname2+='.pt'\n",
    "                \n",
    "                torch.save(model.state_dict(),savepath+modelname2)\n",
    "\n",
    "\n",
    "        now2=datetime.datetime.now()\n",
    "        print(now2-now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef725ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='testsavepath/'\n",
    "phases=['training','val','test']\n",
    "#modeltemp=efficientnetb0().to(device)\n",
    "for modelname in ['b0']:\n",
    "    for batchsize in [200,400,800]:\n",
    "        for learningrate in [0.1,0.01,0.001]:\n",
    "            for weightdecay in [0,0.001]: \n",
    "\n",
    "                if modelname=='b0':\n",
    "                    model=efficientnetb0().to(device)\n",
    "                elif modelname=='b1':\n",
    "                    model=efficientnetb1().to(device)\n",
    "                else:\n",
    "                    model=efficientnetb2().to(device)\n",
    "\n",
    "                print('===================================================')\n",
    "                print(modelname,batchsize,learningrate,weightdecay)\n",
    "\n",
    "                model.to(device)\n",
    "\n",
    "                if torch.cuda.device_count()>1:\n",
    "                    print(f\"using all {torch.cuda.device_count()} GPUs\")\n",
    "                    model=nn.DataParallel(model.to(device))\n",
    "\n",
    "\n",
    "                pipeline(df_train,df_val,df_test,batchsize,learningrate,weightdecay,300,'Adam',\"label\",phases,model,modelname,save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e793b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
